{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Benchmarking on One Machine \n",
    "=========\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Typical User Experience**\n",
    "\n",
    "Laptop Specs:\n",
    "    \n",
    "    Intel Core i7\n",
    "    16gb RAM\n",
    "    NVIDIA GeForce GTX 965M 2GB GDDR5 memory \n",
    "    Microsoft Windows 10\n",
    "    Running Jupyter Notebooks and multiple programs in the background"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import HTML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<script>\n",
       "  function code_toggle() {\n",
       "    if (code_shown){\n",
       "      $('div.input').hide('500');\n",
       "      $('#toggleButton').val('Show Code')\n",
       "    } else {\n",
       "      $('div.input').show('500');\n",
       "      $('#toggleButton').val('Hide Code')\n",
       "    }\n",
       "    code_shown = !code_shown\n",
       "  }\n",
       "\n",
       "  $( document ).ready(function(){\n",
       "    code_shown=false;\n",
       "    $('div.input').hide()\n",
       "  });\n",
       "</script>\n",
       "<form action=\"javascript:code_toggle()\"><input type=\"submit\" id=\"toggleButton\" value=\"Show Code\"></form>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "HTML('''<script>\n",
    "  function code_toggle() {\n",
    "    if (code_shown){\n",
    "      $('div.input').hide('500');\n",
    "      $('#toggleButton').val('Show Code')\n",
    "    } else {\n",
    "      $('div.input').show('500');\n",
    "      $('#toggleButton').val('Hide Code')\n",
    "    }\n",
    "    code_shown = !code_shown\n",
    "  }\n",
    "\n",
    "  $( document ).ready(function(){\n",
    "    code_shown=false;\n",
    "    $('div.input').hide()\n",
    "  });\n",
    "</script>\n",
    "<form action=\"javascript:code_toggle()\"><input type=\"submit\" id=\"toggleButton\" value=\"Show Code\"></form>''')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Import Packages**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.simplefilter(action='ignore')\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import os\n",
    "\n",
    "import time #cpu time\n",
    "import psutil #memory usage\n",
    "#tensorflow\n",
    "import tensorflow as tf\n",
    "\n",
    "#Scikitlearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.datasets import load_svmlight_file\n",
    "from scipy.sparse import coo_matrix,csr_matrix,lil_matrix\n",
    "from sklearn import linear_model\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "# For Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "#displays better in jupyter notebooks\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Download data \n",
    "#!wget https://www.csie.ntu.edu.tw/~cjlin/libsvmtools/datasets/binary/a1a.t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(file):\n",
    "    data = load_svmlight_file(file)#avazu-app.tr.bz2\n",
    "    return data[0], data[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here is the memory baseline before importing data:\n",
      " svmem(total=17101512704, available=9795440640, percent=42.7, used=7306072064, free=9795440640)\n"
     ]
    }
   ],
   "source": [
    "mem_baseline=psutil.virtual_memory() #  physical memory usage\n",
    "print('Here is the memory baseline before importing data:\\n',mem_baseline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y =get_data('a1a.t') #import raw data\n",
    "mem_InData=psutil.virtual_memory()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here is the memory usage after importing data:\n",
      " svmem(total=17101512704, available=9743892480, percent=43.0, used=7357620224, free=9743892480)\n",
      "\n",
      "The time took to import the raw data:\n",
      "550 ms ± 107 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "print('Here is the memory usage after importing data:\\n',mem_InData) #  physical memory usage\n",
    "print('\\nThe time took to import the raw data:')\n",
    "exec_time1 = %%timeit -o X, y =get_data('a1a.t') #import raw data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%timeit\n",
    "#X, y =get_data('a1a.t.bz2') #import binary data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here is the sparse matrix format for the data:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<30956x123 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 429343 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('Here is the sparse matrix format for the data:') \n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#May not be appropriate for time dependant data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Execute Logistic Regression in SciKit Learn\n",
    "-------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# instantiate a logistic regression model, and fit with X and y\n",
    "# Here are the \n",
    "model = linear_model.LogisticRegression(penalty='l2',\\\n",
    "                                        C=1.0,\\\n",
    "                                        tol=0.0001,\\\n",
    "                                        fit_intercept=True,\\\n",
    "                                        n_jobs=1,\\\n",
    "                                        max_iter=100)\n",
    "start = time.time()\n",
    "model = model.fit(X, y.ravel())\n",
    "end = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The time taken to execute the logistic regression: 1.3263437747955322 seconds\n"
     ]
    }
   ],
   "source": [
    "exec_time2=(end - start)\n",
    "print('The time taken to execute the logistic regression:',exec_time2,'seconds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_test)\n",
    "y_obs = y_test\n",
    "y_score = y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Model Metrics**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The correlation coefficient: 0.1588200017358622 \n",
      "The accuracy of the model: 0.8501928640308583 \n",
      "The precision (tp / (tp + fp)): 0.7191295546558705 \n",
      "The recall (tp / (tp + fn)): 0.5874328234807772 \n",
      "The f1 score is: 0.6466439135381115 \n",
      "The Area Under the Curve score is: 0.7581257999666293\n"
     ]
    }
   ],
   "source": [
    "r2=metrics.r2_score(y_obs, y_pred)\n",
    "accuracy=model.score(X_train, y_train)\n",
    "prec=metrics.precision_score(y_obs, y_pred, labels=None, pos_label=1)\n",
    "recall=metrics.recall_score(y_obs, y_pred, labels=None, pos_label=1)\n",
    "f1 = metrics.f1_score(y_obs,y_pred)\n",
    "ROC_AUC = metrics.roc_auc_score(y_obs, y_score)\n",
    "print('The correlation coefficient:',r2,\\\n",
    "      '\\nThe accuracy of the model:',accuracy,\\\n",
    "      '\\nThe precision (tp / (tp + fp)):',prec,\\\n",
    "      '\\nThe recall (tp / (tp + fn)):',recall,\\\n",
    "      '\\nThe f1 score is:',f1,\\\n",
    "      '\\nThe Area Under the Curve score is:',ROC_AUC)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Execute Logistic Regression in Tensorflow\n",
    "-------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here the GPU is used for the task but restricted to using only 75% of GPU resources in order to prevent crashing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 833,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpu_options = tf.GPUOptions(per_process_gpu_memory_fraction=0.75)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 834,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate =  0.01\n",
    "max_iter = 10\n",
    "batch_size = 30\n",
    "\n",
    "train_file = os.getcwd()+'\\\\tensorflow-models\\\\data\\\\libsvm_data\\\\a1a'\n",
    "test_file = os.getcwd()+'\\\\tensorflow-models\\\\data\\\\libsvm_data\\\\a1a.t'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 848,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataSet(object):\n",
    "    feature_num=1\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.iter = 0\n",
    "        self.epoch_pass = 0\n",
    "        self.new_num = DataSet.feature_num    \n",
    "        \n",
    "    def update_num(new_num):\n",
    "        while DataSet.feature_num<new_num:\n",
    "            DataSet.feature_num=new_num\n",
    "            return DataSet.feature_num\n",
    "    \n",
    "    def load(self, file):\n",
    "        self.ins_num = 0\n",
    "        f = open(file, \"r\")\n",
    "        self.y = []\n",
    "        self.feature_ids = []\n",
    "        self.feature_values = []\n",
    "        self.ins_feature_interval = []\n",
    "        self.ins_feature_interval.append(0)\n",
    "\n",
    "        for line in f.readlines():\n",
    "            tokens = line.split(\" \")\n",
    "            self.y.append(float(tokens[0]))\n",
    "            self.ins_feature_interval.append(self.ins_feature_interval[-1] + len(tokens) - 1)\n",
    "            #for feature in tokens[1:]:\n",
    "            regexp = re.compile(r':')\n",
    "            for feature in tokens:\n",
    "                if regexp.search(feature):\n",
    "                    feature_id, feature_value = feature.split(\":\")#feature number should be max of the list, match to feature\n",
    "                    if int(feature_id)>=0:\n",
    "                        self.feature_ids.append(int(feature_id))\n",
    "                        self.feature_values.append(float(feature_value)) \n",
    "                        #print(feature_id)\n",
    "            self.ins_num += 1 \n",
    "        return DataSet.update_num(max(self.feature_ids))\n",
    "\n",
    "    def mini_batch(self, batch_size):\n",
    "        begin = self.iter\n",
    "        end = self.iter\n",
    "        if self.iter + batch_size > self.ins_num:\n",
    "            end = self.ins_num\n",
    "            self.iter = 0\n",
    "            self.epoch_pass += 1\n",
    "        else:\n",
    "            end += batch_size\n",
    "            self.iter = end\n",
    "            #print(begin,end)\n",
    "            #print(self.slice(begin, end))\n",
    "        return self.slice(begin, end)\n",
    "\n",
    "    def slice(self, begin, end):\n",
    "        sparse_index = []\n",
    "        sparse_ids = []\n",
    "        sparse_values = []\n",
    "        sparse_shape = []\n",
    "        max_feature_num = 0\n",
    "        \n",
    "        for i in range(begin, end):\n",
    "            #print([begin,end])\n",
    "            DataSet.feature_num = self.ins_feature_interval[i + 1] - self.ins_feature_interval[i]\n",
    "            #print(self.ins_feature_interval[i + 1] - self.ins_feature_interval[i])\n",
    "            if DataSet.feature_num > max_feature_num:\n",
    "                max_feature_num = DataSet.feature_num\n",
    "                #print(max_feature_num)\n",
    "            for j in range(self.ins_feature_interval[i], self.ins_feature_interval[i + 1]): \n",
    "                #print(range(self.ins_feature_interval[i], self.ins_feature_interval[i + 1]))\n",
    "                sparse_index.append([i - begin, j - self.ins_feature_interval[i]]) # index must be accent\n",
    "                #print([i - begin, j - self.ins_feature_interval[i]])\n",
    "                sparse_ids.append((self.feature_ids[j]))#<----\n",
    "                #print(self.feature_ids[j])\n",
    "                sparse_values.append(self.feature_values[j])\n",
    "                #print(self.feature_values[j])\n",
    "                \n",
    "            sparse_shape.append(end - begin)\n",
    "            #print(sparse_shape)\n",
    "            sparse_shape.append(max_feature_num)\n",
    "            #print(sparse_shape)\n",
    "            y = np.array(self.y[begin:end]).reshape((end - begin, 1))\n",
    "            #print(len(sparse_index), len(sparse_ids), len(sparse_values), len(sparse_shape), len(y))\n",
    "            #print(sparse_index)\n",
    "            #print(sparse_ids)\n",
    "            #print(sparse_values)\n",
    "            #print(sparse_shape)\n",
    "            #print(y)\n",
    "            return (sparse_index, sparse_ids, sparse_values, sparse_shape, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 849,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_set.mini_batch(batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 850,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 850,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DataSet.feature_num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 851,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BinaryLogisticRegression(object):\n",
    "    def __init__(self, feature_num):\n",
    "        self.feature_num = feature_num\n",
    "        self.sparse_index = tf.placeholder(tf.int64)\n",
    "        self.sparse_ids = tf.placeholder(tf.int64)\n",
    "        self.sparse_values = tf.placeholder(tf.float32)\n",
    "        self.sparse_shape = tf.placeholder(tf.int64)\n",
    "        self.w = tf.Variable(tf.random_normal([self.feature_num, 1], stddev=0.1))\n",
    "        self.y = tf.placeholder(\"float\", [None, 1])\n",
    "\n",
    "    def forward(self):\n",
    "        return tf.nn.embedding_lookup_sparse(self.w,\n",
    "                                             tf.SparseTensor(self.sparse_index, self.sparse_ids, self.sparse_shape),\n",
    "                                             tf.SparseTensor(self.sparse_index, self.sparse_values, self.sparse_shape),\n",
    "                                             combiner=\"sum\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 852,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "119"
      ]
     },
     "execution_count": 852,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_set = DataSet()\n",
    "train_set.load(train_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 853,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "123"
      ]
     },
     "execution_count": 853,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_set = DataSet()\n",
    "test_set.load(test_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 854,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = BinaryLogisticRegression(DataSet.feature_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 855,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = model.forward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 856,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = tf.reduce_sum(tf.nn.sigmoid_cross_entropy_with_logits(labels=y, logits=model.y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 857,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate).minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 858,
   "metadata": {},
   "outputs": [],
   "source": [
    "probability_output = tf.nn.sigmoid(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 859,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[None, None]"
      ]
     },
     "execution_count": 859,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "session = tf.Session()\n",
    "init_all_variable = tf.global_variables_initializer()\n",
    "init_local_variable = tf.local_variables_initializer()\n",
    "session.run([init_all_variable, init_local_variable])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 860,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-860-08d017e34699>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mwhile\u001b[0m \u001b[0mtrain_set\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mepoch_pass\u001b[0m \u001b[1;33m<\u001b[0m \u001b[0mmax_iter\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m     \u001b[0msparse_index\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msparse_ids\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msparse_values\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msparse_shape\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmb_y\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_set\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmini_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     _, loss_, prob_out = session.run([optimizer, loss, probability_output],\n\u001b[0;32m      5\u001b[0m                                      feed_dict={model.sparse_index: sparse_index,\n",
      "\u001b[1;32m<ipython-input-848-515cf2215063>\u001b[0m in \u001b[0;36mmini_batch\u001b[1;34m(self, batch_size)\u001b[0m\n\u001b[0;32m     49\u001b[0m             \u001b[1;31m#print(begin,end)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     50\u001b[0m             \u001b[1;31m#print(self.slice(begin, end))\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 51\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mslice\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbegin\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mend\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     52\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     53\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mslice\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbegin\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mend\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-848-515cf2215063>\u001b[0m in \u001b[0;36mslice\u001b[1;34m(self, begin, end)\u001b[0m\n\u001b[0;32m     69\u001b[0m                 \u001b[0msparse_index\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mbegin\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mj\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mins_feature_interval\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# index must be accent\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     70\u001b[0m                 \u001b[1;31m#print([i - begin, j - self.ins_feature_interval[i]])\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 71\u001b[1;33m                 \u001b[0msparse_ids\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfeature_ids\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mj\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;31m#<----\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     72\u001b[0m                 \u001b[1;31m#print(self.feature_ids[j])\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     73\u001b[0m                 \u001b[0msparse_values\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfeature_values\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mj\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "while train_set.epoch_pass < max_iter:\n",
    "    sparse_index, sparse_ids, sparse_values, sparse_shape, mb_y = train_set.mini_batch(batch_size)\n",
    "\n",
    "    _, loss_, prob_out = session.run([optimizer, loss, probability_output],\n",
    "                                     feed_dict={model.sparse_index: sparse_index,\n",
    "                                                model.sparse_ids: sparse_ids,\n",
    "                                                model.sparse_values: sparse_values,\n",
    "                                                model.sparse_shape: sparse_shape,\n",
    "                                                model.y: mb_y})\n",
    "\n",
    "auc = roc_auc_score(mb_y, prob_out)\n",
    "print(\"epoch: \", train_set.epoch_pass, \" auc: \", auc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#for loop to create our own timeit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
