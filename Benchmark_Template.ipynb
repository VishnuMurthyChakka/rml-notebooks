{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Benchmarking: One Machine \n",
    "=========\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Typical User Experience**\n",
    "\n",
    "Laptop Specs:\n",
    "    \n",
    "    Intel Core i7\n",
    "    16gb RAM\n",
    "    NVIDIA GeForce GTX 965M 2GB GDDR5 memory \n",
    "    Microsoft Windows 10\n",
    "    Running Jupyter Notebooks and multiple programs in the background"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import HTML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "HTML('''<script>\n",
    "  function code_toggle() {\n",
    "    if (code_shown){\n",
    "      $('div.input').hide('500');\n",
    "      $('#toggleButton').val('Show Code')\n",
    "    } else {\n",
    "      $('div.input').show('500');\n",
    "      $('#toggleButton').val('Hide Code')\n",
    "    }\n",
    "    code_shown = !code_shown\n",
    "  }\n",
    "\n",
    "  $( document ).ready(function(){\n",
    "    code_shown=false;\n",
    "    $('div.input').hide()\n",
    "  });\n",
    "</script>\n",
    "<form action=\"javascript:code_toggle()\"><input type=\"submit\" id=\"toggleButton\" value=\"Show Code\"></form>''')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Import Packages**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow version: 1.9.0\n",
      "SciKit-Learn version: 0.20.0\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.simplefilter(action='ignore')\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import os\n",
    "\n",
    "import time #cpu time\n",
    "import psutil #memory usage\n",
    "\n",
    "#tensorflow\n",
    "import tensorflow as tf\n",
    "\n",
    "#Scikit-learn\n",
    "import sklearn as sk\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.datasets import load_svmlight_file\n",
    "from sklearn.datasets import dump_svmlight_file\n",
    "\n",
    "\n",
    "from scipy.sparse import coo_matrix,csr_matrix,lil_matrix\n",
    "from sklearn import linear_model\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "\n",
    "# For Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "#displays better in jupyter notebooks\n",
    "%matplotlib inline\n",
    "\n",
    "print('TensorFlow version: {0}'.format(tf.__version__))\n",
    "print('SciKit-Learn version: {0}'.format(sk.__version__))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For benchmarking to start with we are using LIBSVM's **Avazu-App data** "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Source(s)**: \n",
    "\n",
    "LIBSVM Data Classification: https://www.csie.ntu.edu.tw/~cjlin/libsvmtools/datasets/binary.html#a1a\n",
    "\n",
    "Avazu's Click-through Prediction https://www.kaggle.com/c/avazu-ctr-prediction/data\n",
    "\n",
    "**Preprocessing**: This data is used in a competition on click-through rate prediction jointly hosted by Avazu and Kaggle in 2014. The participents were asked to learn a model from the first 10 days of advertising log, and predict the click probability for the impressions on the 11th day. The data sets here are generated by applying our winning solution without some complicated components. To reproduce this data, you can execute our code and see the results in the directory \"base.\" For better test scores, we divide the data to two disjoint groups \"app\" and \"site,\" and conduct training and prediction tasks on the two groups independetly. Specifically, each instance has either \"site_id=85f751fd\" or \"app_id=ecad2386,\" and these two feature values never co-occur. Thus we can split the data set according to them. The organizers do not disclose the test labels, so the labels in the test sets are not meaningful. To obtain a test score, please use the code provided below to generate and submit a file to the competition site. Because data are timely dependent, cross validation is not suitable for parameter selection. We provide a training-validation split (e.g., \"avazu-app.tr\" and \"avazu-app.val\") by consider the last 4,218,938 training instances for validation. [YJ16a]\n",
    "\n",
    "- Number of classes: 2\n",
    "\n",
    "- Number of data: 40,428,967 / 4,577,464 (testing) / 14,596,137 (avazu-app) / 1,719,304 (avazu-app.t) / 12,642,186 (avazu-app.tr) / 1,953,951 (avazu-app.val) / 25,832,830 (avazu-site) / 2,858,160 (avazu-site.t) / 23,567,843 (avazu-site.tr) / 2,264,987 (avazu-site.val)\n",
    "\n",
    "    Number of features: 1,000,000\n",
    "Files:\n",
    "\n",
    "- avazu-app.bz2 (app) https://www.csie.ntu.edu.tw/~cjlin/libsvmtools/datasets/binary/avazu-app.bz2\n",
    "- avazu-app.t.bz2 (app's testing) https://www.csie.ntu.edu.tw/~cjlin/libsvmtools/datasets/binary/avazu-app.t.bz2\n",
    "- avazu-app.tr.bz2 (app's tr) https://www.csie.ntu.edu.tw/~cjlin/libsvmtools/datasets/binary/avazu-app.tr.bz2\n",
    "- avazu-app.val.bz2 (app's val) https://www.csie.ntu.edu.tw/~cjlin/libsvmtools/datasets/binary/avazu-app.val.bz2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Download data*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Download data \n",
    "\n",
    "#!wget https://www.csie.ntu.edu.tw/~cjlin/libsvmtools/datasets/binary/avazu-app.bz2 #<---full app data\n",
    "#!wget https://www.csie.ntu.edu.tw/~cjlin/libsvmtools/datasets/binary/avazu-app.tr.bz2 #<---benchmark training\n",
    "#!wget https://www.csie.ntu.edu.tw/~cjlin/libsvmtools/datasets/binary/avazu-app.t.bz2 #<---benchmark testing\n",
    "#!wget https://www.csie.ntu.edu.tw/~cjlin/libsvmtools/datasets/binary/avazu-app.val.bz2 #<---benchmark validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extracting Files:\n",
    "    \n",
    "    For Scikitlearn extracting the files is unnecessary since the load_svm_light_file with automatically extract .bz2 files. However for Tensorflow will need them already extracted to have comparable results. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!bzip2 -dk avazu-app.bz2 #Extract full data \n",
    "#!bzip2 -dk avazu-app.tr.bz2 #Extract Training\n",
    "#!bzip2 -dk avazu-app.t.bz2 #Extract Testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Classes and Functions***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Data importing function\n",
    "#scipy.sparse matrix of shape (n_samples, n_features)\n",
    "\n",
    "def get_data(file):\n",
    "    data = load_svmlight_file(file)#avazu-app.tr.bz2\n",
    "    return data[0], data[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**For Importing Raw Individual File**\n",
    "\n",
    "*If the data is in a single file that hasn't already been seperated in training and testing datasets.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mem_baseline=psutil.virtual_memory() #  physical memory usage\n",
    "print('Here is the memory baseline prior to importing data:\\n',mem_baseline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_location=os.getcwd()+'/avazu-app'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y=get_data(file_location) #import raw data\n",
    "mem_InData=psutil.virtual_memory()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Here is the memory usage after importing data:\\n',mem_InData) #  physical memory usage\n",
    "print('\\nThe time taken to import the raw data:')\n",
    "exec_time1 = %%timeit -o X, y =get_data(file_location) #import raw data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Here is the type of sparse matrix format for the data:')\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('The shape of the X training set:\\n (samples,features)',X_train.shape)\n",
    "print('The shape of the X testing set:\\n (samples,features)',X_test.shape)\n",
    "print('The shape of the Y training set:\\n (samples,features)',y_train.shape)\n",
    "print('The shape of the Y testing set:\\n (samples,features)',y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** For Importing Previously Seperated Training and Testing File**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If the data is already seperated into a training and testing file, you should begin your testing here.              "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Designate file location\n",
    "train_file=os.getcwd()+'\\\\avazu-app.tr'\n",
    "test_file=os.getcwd()+'\\\\avazu-app.t'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mem_baseline=psutil.virtual_memory() #  physical memory usage\n",
    "print('Here is the memory baseline prior to importing data:\\n\\n',mem_baseline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "\n",
    "train_set = DataSet()\n",
    "train_set.load(train_file)\n",
    "\n",
    "end = time.time()\n",
    "exec_time1=(end - start)\n",
    "print('\\nThe time taken to import and prepare training data for Tensorflow is:',exec_time1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "X_train, y_train=get_data(train_file)\n",
    "X_test, y_test=get_data(test_file)\n",
    "\n",
    "end = time.time()\n",
    "exec_time=(end - start)\n",
    "print('Time to import the data into Scikit-Learn:',exec_time,' seconds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mem_baseline=psutil.virtual_memory() #  physical memory usage\n",
    "print('Here is the memory usage afer importing the data:\\n\\n',mem_baseline)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Execute Logistic Regression in SciKit Learn\n",
    "-------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The parameters for the logistic regression (Gradient Descent) are:\n",
    "    \n",
    "    Regularization: L2\n",
    "    \n",
    "    Regularization Threshold (C): 1.0\n",
    "    \n",
    "    Tolerance: 0.001\n",
    "    \n",
    "    Fit Intercpt: Yes (True)\n",
    "    \n",
    "    Processors (n_jobs): 1\n",
    "    \n",
    "    Max Number of Iterations: 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate a logistic regression model, and fit with X and y\n",
    "\n",
    "model = linear_model.LogisticRegression(penalty='l2',\\\n",
    "                                        C=1.0,\\\n",
    "                                        tol=0.001,\\\n",
    "                                        fit_intercept=True,\\\n",
    "                                        n_jobs=1,\\\n",
    "                                        max_iter=100)\n",
    "\n",
    "model = model.fit(X_train, y_train.ravel())#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exec_time2 = %%timeit -o model.fit(X_train, y_train.ravel())\n",
    "print('\\nThe average time taken to execute the logistic regression:',exec_time2,'seconds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Setup variables for evaluation metrics\n",
    "y_pred = model.predict(X_train)\n",
    "y_obs = y_train\n",
    "y_score = y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Model Metrics**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r2=metrics.r2_score(y_obs, y_pred)\n",
    "accuracy=model.score(X_train, y_train)\n",
    "prec=metrics.precision_score(y_obs, y_pred, labels=None, pos_label=1)\n",
    "recall=metrics.recall_score(y_obs, y_pred, labels=None, pos_label=1)\n",
    "f1 = metrics.f1_score(y_obs,y_pred)\n",
    "ROC_AUC = metrics.roc_auc_score(y_obs, y_score)\n",
    "print('The correlation coefficient:',r2,\\\n",
    "      '\\nThe accuracy of the model:',accuracy,\\\n",
    "      '\\nThe precision (tp / (tp + fp)):',prec,\\\n",
    "      '\\nThe recall (tp / (tp + fn)):',recall,\\\n",
    "      '\\nThe f1 score is:',f1,\\\n",
    "      '\\nThe Area Under the Curve score is:',ROC_AUC)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Execute Logistic Regression in Tensorflow\n",
    "-------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*For splitting data file*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data file has been train/test split.\n"
     ]
    }
   ],
   "source": [
    "input_file=os.getcwd()+'\\\\avazu-app.t'\n",
    "\n",
    "X,y=get_data(input_file)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "dump_svmlight_file(X_train, y_train,'train_file')#%80\n",
    "dump_svmlight_file(X_test, y_test,'test_file')#%20\n",
    "print('Data file has been train/test split.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here the GPU is used for the task but restricted to using only 75% of GPU resources in order to prevent crashing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpu_options = tf.GPUOptions(per_process_gpu_memory_fraction=0.75)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Classes and Functions***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataSet(object):\n",
    "    def __init__(self):\n",
    "        self.iter = 0\n",
    "        self.epoch_pass = 0\n",
    "\n",
    "    def load(self, file, features, length):\n",
    "        '''\n",
    "         1. Each line is read and split by white space, then appends the first value of matrix as y's. \n",
    "         2. Then counts the number of pairs (int:int) represented by each y and stores that. \n",
    "         3. Then splits pairs (int:int) where the first value represents the sparse ids,\n",
    "                  and the second value is the sparse value\n",
    "        '''\n",
    "        X, y=load_svmlight_file(file,n_features=features,zero_based=True,length=length)\n",
    "        self.feature_num=X.shape[1] #The number of cols in X set\n",
    "        self.ins_num =X.shape[0] #The number of rows in X set\n",
    "        self.y = list(y)\n",
    "        self.feature_ids = list(X.indices) #column index\n",
    "        self.feature_value = list(X.data) #values\n",
    "        self.ins_feature_interval =list(X.indptr) #row starts \n",
    "        self.ins_feature_interval_diff = [(j-i) for i, j in zip(X.indptr[:-1], X.indptr[1:])] #difference between row start records\n",
    "    \n",
    "\n",
    "    def mini_batch(self, batch_size):\n",
    "        '''\n",
    "        0. Ultimately this function creates slice boundaries of (batch size).\n",
    "        1. Initially sets beginning and end bounds equivalent to iteration count starting at zero\n",
    "        2.       if the iteration count plus batch size is greater than the number of records\n",
    "        3. set the end bound equal to record size, then reset iteration to 0 and record that 1 epoch has been achieved\n",
    "            (i.e keep adding the end bounds together until end of dataset then record that 1 pass is complete)\n",
    "        4. Otherwise-\n",
    "            keep adding batch size to end bound then set iteration to end bound \n",
    "            thus a batch size of 100 will set end bound (0,100,200,300,400)\n",
    "                note: begin is set to iteration so when it goes through the loop--\n",
    "                begin will be 1 batch size smaller than end bound until records limit is reached\n",
    "        '''\n",
    "        begin = self.iter #begins as 0 as defined above\n",
    "        end = self.iter #starts with 0 as defined above\n",
    "        if self.iter + batch_size > self.ins_num: #if 0 + batchsize(10) > ins_num(1) defined in def load\n",
    "            end = self.ins_num #set end to be ins_num(1) \n",
    "            self.iter = 0 #set iter to 0\n",
    "            self.epoch_pass += 1 #add +1 to epoch_pass \n",
    "        else:\n",
    "            end += batch_size#add batch size to end, which should be equal to batch size\n",
    "            self.iter = end#set self.iter to batch size\n",
    "        return self.slice(begin, end)\n",
    "\n",
    "    def slice(self, begin, end):\n",
    "        '''\n",
    "        This function does the actual slicing of batch sizes and creates objects used to pass into SparseTensor. \n",
    "        The format should look like this:\n",
    "        SparseTensor(indices=[[0, 0], [0, 1]...], values=[1,1,1...], dense_shape=[1000, 15])\n",
    "        '''\n",
    "        sparse_index = []\n",
    "        sparse_ids = list(train_set.feature_ids[train_set.ins_feature_interval[begin]:train_set.ins_feature_interval[end]])\n",
    "        sparse_values = list(self.feature_value[self.ins_feature_interval[begin]:self.ins_feature_interval[end]])\n",
    "        sparse_shape = [end - begin,max(self.ins_feature_interval_diff)]\n",
    "        y = np.array(self.y[begin:end]).reshape((end - begin, 1))\n",
    "        for i in range(begin, end):\n",
    "            for j in range(self.ins_feature_interval[i], self.ins_feature_interval[i + 1]):\n",
    "                sparse_index.append([i - begin, j - self.ins_feature_interval[i]]) \n",
    "        return (sparse_index, sparse_ids, sparse_values, sparse_shape, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BinaryLogisticRegression(object):\n",
    "    def __init__(self, feature_num):\n",
    "        self.feature_num = feature_num\n",
    "        self.sparse_index = tf.placeholder(tf.int64)\n",
    "        self.sparse_ids = tf.placeholder(tf.int64)\n",
    "        self.sparse_values = tf.placeholder(tf.float32)\n",
    "        self.sparse_shape = tf.placeholder(tf.int64)\n",
    "        self.w = tf.Variable(tf.random_normal([self.feature_num, 1], stddev=0.1))\n",
    "        self.y = tf.placeholder(\"float\", [None, 1])\n",
    "\n",
    "    def forward(self):\n",
    "        return tf.nn.embedding_lookup_sparse(self.w,\n",
    "                                             tf.SparseTensor(self.sparse_index, self.sparse_ids, self.sparse_shape),\n",
    "                                             tf.SparseTensor(self.sparse_index, self.sparse_values, self.sparse_shape),\n",
    "                                             combiner=\"sum\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here is the memory baseline prior to importing data:\n",
      "\n",
      " svmem(total=17101512704, available=7341273088, percent=57.1, used=9760239616, free=7341273088)\n"
     ]
    }
   ],
   "source": [
    "mem_baseline1=psutil.virtual_memory() #  physical memory usage\n",
    "print('Here is the memory baseline prior to importing data:\\n\\n',mem_baseline1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate =  0.001\n",
    "max_iter = 10\n",
    "batch_size = 1000\n",
    "feature_num=1000000\n",
    "\n",
    "train_file=os.getcwd()+'\\\\avazu-app.tr'\n",
    "test_file=os.getcwd()+'\\\\avazu-app.t'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "The time taken to import and prepare training data for Tensorflow is: 6.182252645492554\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "\n",
    "train_set = DataSet()\n",
    "train_set.load(train_file,feature_num,40428967)\n",
    "\n",
    "end = time.time()\n",
    "exec_time1=(end - start)\n",
    "print('\\nThe time taken to import and prepare training data for Tensorflow is:',exec_time1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "The time taken to import and prepare testing data for Tensorflow is: 0.7349328994750977\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "\n",
    "test_set = DataSet()\n",
    "test_set.load(test_file,feature_num,4577464)\n",
    "\n",
    "end = time.time()\n",
    "exec_time2=(end - start)\n",
    "print('\\nThe time taken to import and prepare testing data for Tensorflow is:',exec_time2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here is the memory usage after importing data:\n",
      " svmem(total=17101512704, available=7266021376, percent=57.5, used=9835491328, free=7266021376)\n"
     ]
    }
   ],
   "source": [
    "mem_baseline2=psutil.virtual_memory() #  physical memory usage\n",
    "print('Here is the memory usage after importing data:\\n',mem_baseline2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = BinaryLogisticRegression(feature_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = model.forward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = tf.reduce_sum(tf.nn.sigmoid_cross_entropy_with_logits(labels=y, logits=model.y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate).minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "probability_output = tf.nn.sigmoid(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[None, None]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "session = tf.Session()\n",
    "init_all_variable = tf.global_variables_initializer()\n",
    "init_local_variable = tf.local_variables_initializer()\n",
    "session.run([init_all_variable, init_local_variable])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set number of passes in for loop. \n",
    "\n",
    "*This is done primarily for timing purposes to get an average calculation time.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_passes=1 #number of passes in for loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:  10  Receiver Operating Curve, Area Under the Curve score is:  0.5047846889952153\n",
      "\n",
      "The average time taken to execute logistic regression for 1 full passes of 10 iterations took 183.83894801139832 seconds with a standard deviation of +- 0.0\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "end_list=[]\n",
    "for i in range(0,num_passes):\n",
    "    while train_set.epoch_pass < max_iter:\n",
    "        #fills values in batch units while for each epoch pass in less than max_iterations\n",
    "        sparse_index, sparse_ids, sparse_values, sparse_shape, mb_y = train_set.mini_batch(batch_size)\n",
    "        \n",
    "        _, loss_, prob_out = session.run([optimizer, loss, probability_output],\n",
    "                                         feed_dict={model.sparse_index: sparse_index,\n",
    "                                                    model.sparse_ids: sparse_ids,\n",
    "                                                    model.sparse_values: sparse_values,\n",
    "                                                    model.sparse_shape: sparse_shape,\n",
    "                                                    model.y: mb_y})\n",
    "        \n",
    "    end = time.time()\n",
    "    exec_time=(end - start)\n",
    "    end_list.append(exec_time) \n",
    "    #save endlist not exec_time\n",
    "    try:\n",
    "        auc = roc_auc_score(mb_y, prob_out)\n",
    "        print(\"epoch: \", train_set.epoch_pass, \" Receiver Operating Curve, Area Under the Curve score is: \", auc)\n",
    "\n",
    "    except:\n",
    "        print('\\nValueError: Only one class present in y_true. ROC AUC score is not defined in that case.\\n')\n",
    "        print(mb_y.T)\n",
    "        print(prob_out.T,'\\n')\n",
    "\n",
    "print('\\nThe average time taken to execute logistic regression for '+str(num_passes)+' full passes of',max_iter,'iterations took',np.array(end_list).mean(),'seconds with a standard deviation of +- '+str(np.array(end_list).std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "bench_list=[str(mem_baseline1),str(exec_time1),str(exec_time2),str(mem_baseline2),str(np.array(end_list).mean())]\n",
    "with open('bench_times.txt', 'w') as f:\n",
    "    for item in bench_list:\n",
    "        f.write(\"%s\\n\" % item)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_____________________________________"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Benchmarks\n",
    "======"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scikit Learn AWS c5.2xlarge\n",
    "-------\n",
    "\n",
    "**SciKitLearn Before importing:**  svmem(total=16222670848, available=15447273472, percent=4.8, used=425279488, free=11094663168, active=2583482368, inactive=2261311488, buffers=263196672, cached=4439531520, shared=21082112, slab=169435136)\n",
    "    \n",
    "**SciKitLearn After importing:** svmem(total=16222670848, available=12618625024, percent=22.2, used=3253944320, free=6678728704, active=8217722880, inactive=1035603968, buffers=263544832, cached=6026452992, shared=21082112, slab=169373696)\n",
    "\n",
    "**SciKitLearn time to import**: 132.54389119148254 seconds\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "***Average Calculation Time:***\n",
    "    \n",
    "**SciKitLearn:**\n",
    "1 loop, best of 3: 9min 55s per loop\n",
    "('\\nThe average time taken to execute the logistic regression:', <IPython.core.magics.execution.TimeitResult object at 0x7fdb87730fd0>, 'seconds')\n",
    "\n",
    "Tensorflow AWS c5.2xlarge\n",
    "-------------\n",
    "\n",
    "**Tensorflow Before importing:**  svmem(total=16222670848, available=15502614528, percent=4.4, used=352391168, free=1381421056, active=5944606720, inactive=8003710976, buffers=438689792, cached=14050168832, shared=21106688, slab=780996608)\n",
    "    \n",
    "**Tensorflow After importing:** svmem(total=16222670848, available=15418843136, percent=5.0, used=436162560, free=1297649664, active=6027079680, inactive=8003710976, buffers=438689792, cached=14050168832, shared=21106688, slab=780820480)\n",
    "\n",
    "**Tensorflow time to import**: \n",
    "The time taken to import and prepare training data for Tensorflow is: 0.6254868507385254\n",
    "The time taken to import and prepare testing data for Tensorflow is: 0.08609414100646973\n",
    "\n",
    "\n",
    "***Average Calculation Time:***\n",
    "    \n",
    "**Tensorflow:**\n",
    "The average time taken to execute logistic regression for 5 full passes of 100 iterations took 411.0613938808441 seconds with a standard deviation of +- 0.0011656490621771976"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
