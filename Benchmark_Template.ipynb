{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Benchmarking on One Machine \n",
    "=========\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Typical User Experience**\n",
    "\n",
    "Laptop Specs:\n",
    "    \n",
    "    Intel Core i7\n",
    "    16gb RAM\n",
    "    NVIDIA GeForce GTX 965M 2GB GDDR5 memory \n",
    "    Microsoft Windows 10\n",
    "    Running Jupyter Notebooks and multiple programs in the background"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<script>\n",
       "  function code_toggle() {\n",
       "    if (code_shown){\n",
       "      $('div.input').hide('500');\n",
       "      $('#toggleButton').val('Show Code')\n",
       "    } else {\n",
       "      $('div.input').show('500');\n",
       "      $('#toggleButton').val('Hide Code')\n",
       "    }\n",
       "    code_shown = !code_shown\n",
       "  }\n",
       "\n",
       "  $( document ).ready(function(){\n",
       "    code_shown=false;\n",
       "    $('div.input').hide()\n",
       "  });\n",
       "</script>\n",
       "<form action=\"javascript:code_toggle()\"><input type=\"submit\" id=\"toggleButton\" value=\"Show Code\"></form>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "HTML('''<script>\n",
    "  function code_toggle() {\n",
    "    if (code_shown){\n",
    "      $('div.input').hide('500');\n",
    "      $('#toggleButton').val('Show Code')\n",
    "    } else {\n",
    "      $('div.input').show('500');\n",
    "      $('#toggleButton').val('Hide Code')\n",
    "    }\n",
    "    code_shown = !code_shown\n",
    "  }\n",
    "\n",
    "  $( document ).ready(function(){\n",
    "    code_shown=false;\n",
    "    $('div.input').hide()\n",
    "  });\n",
    "</script>\n",
    "<form action=\"javascript:code_toggle()\"><input type=\"submit\" id=\"toggleButton\" value=\"Show Code\"></form>''')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Import Packages**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 657,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from IPython.display import HTML\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore')\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "import time #cpu time\n",
    "import psutil #memory usage\n",
    "#tensorflow\n",
    "import tensorflow as tf\n",
    "\n",
    "#Scikitlearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.datasets import load_svmlight_file\n",
    "from scipy.sparse import coo_matrix,csr_matrix,lil_matrix\n",
    "from sklearn import linear_model\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "# For Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "#displays better in jupyter notebooks\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 658,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Download data \n",
    "#!wget https://www.csie.ntu.edu.tw/~cjlin/libsvmtools/datasets/binary/a1a.t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 659,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(file):\n",
    "    data = load_svmlight_file(file)#avazu-app.tr.bz2\n",
    "    return data[0], data[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 660,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here is the memory baseline before importing data:\n",
      " svmem(total=17101512704, available=8536772608, percent=50.1, used=8564740096, free=8536772608)\n"
     ]
    }
   ],
   "source": [
    "mem_baseline=psutil.virtual_memory() #  physical memory usage\n",
    "print('Here is the memory baseline before importing data:\\n',mem_baseline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 661,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y =get_data('a1a.t') #import raw data\n",
    "mem_InData=psutil.virtual_memory()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 662,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here is the memory usage after importing data:\n",
      " svmem(total=17101512704, available=8533667840, percent=50.1, used=8567844864, free=8533667840)\n",
      "\n",
      "The time took to import the raw data:\n",
      "229 ms ± 9.36 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "print('Here is the memory usage after importing data:\\n',mem_InData) #  physical memory usage\n",
    "print('\\nThe time took to import the raw data:')\n",
    "exec_time1 = %%timeit -o X, y =get_data('a1a.t') #import raw data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 663,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%timeit\n",
    "#X, y =get_data('a1a.t.bz2') #import binary data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 664,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here is the sparse matrix format for the data:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<30956x123 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 429343 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 664,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('Here is the sparse matrix format for the data:') \n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 665,
   "metadata": {},
   "outputs": [],
   "source": [
    "#May not be appropriate for time dependant data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Execute Logistic Regression in SciKit Learn\n",
    "-------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 666,
   "metadata": {},
   "outputs": [],
   "source": [
    "# instantiate a logistic regression model, and fit with X and y\n",
    "# Here are the \n",
    "model = linear_model.LogisticRegression(penalty='l2',\\\n",
    "                                        C=1.0,\\\n",
    "                                        tol=0.0001,\\\n",
    "                                        fit_intercept=True,\\\n",
    "                                        n_jobs=1,\\\n",
    "                                        max_iter=100)\n",
    "start = time.time()\n",
    "model = model.fit(X, y.ravel())\n",
    "end = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 667,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The time taken to execute the logistic regression: 0.6029822826385498 seconds\n"
     ]
    }
   ],
   "source": [
    "exec_time2=(end - start)\n",
    "print('The time taken to execute the logistic regression:',exec_time2,'seconds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 668,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_test)\n",
    "y_obs = y_test\n",
    "y_score = y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Model Metrics**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 669,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The correlation coefficient: 0.1588200017358622 \n",
      "The accuracy of the model: 0.8501928640308583 \n",
      "The precision (tp / (tp + fp)): 0.7191295546558705 \n",
      "The recall (tp / (tp + fn)): 0.5874328234807772 \n",
      "The f1 score is: 0.6466439135381115 \n",
      "The Area Under the Curve score is: 0.7581257999666293\n"
     ]
    }
   ],
   "source": [
    "r2=metrics.r2_score(y_obs, y_pred)\n",
    "accuracy=model.score(X_train, y_train)\n",
    "prec=metrics.precision_score(y_obs, y_pred, labels=None, pos_label=1)\n",
    "recall=metrics.recall_score(y_obs, y_pred, labels=None, pos_label=1)\n",
    "f1 = metrics.f1_score(y_obs,y_pred)\n",
    "ROC_AUC = metrics.roc_auc_score(y_obs, y_score)\n",
    "print('The correlation coefficient:',r2,\\\n",
    "      '\\nThe accuracy of the model:',accuracy,\\\n",
    "      '\\nThe precision (tp / (tp + fp)):',prec,\\\n",
    "      '\\nThe recall (tp / (tp + fn)):',recall,\\\n",
    "      '\\nThe f1 score is:',f1,\\\n",
    "      '\\nThe Area Under the Curve score is:',ROC_AUC)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Execute Logistic Regression in Tensorflow\n",
    "-------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here the GPU is used for the task but restricted to using only 75% of GPU resources in order to prevent crashing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 638,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpu_options = tf.GPUOptions(per_process_gpu_memory_fraction=0.75)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 643,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = []\n",
    "feature_ids = []\n",
    "feature_values = []\n",
    "ins_feature_interval = []\n",
    "\n",
    "learning_rate =  0.01\n",
    "max_iter = 10\n",
    "batch_size = 30\n",
    "feature_num = 123\n",
    "\n",
    "train_file = os.getcwd()+'\\\\tensorflow-models\\\\data\\\\libsvm_data\\\\a8a'\n",
    "test_file = os.getcwd()+'\\\\tensorflow-models\\\\data\\\\libsvm_data\\\\a8a.t'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 644,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataSet(object):\n",
    "    def __init__(self):\n",
    "        self.iter = 0\n",
    "        self.epoch_pass = 0\n",
    "\n",
    "    def load(self, file, feature_num):\n",
    "        self.feature_num = feature_num\n",
    "        self.ins_num = 0\n",
    "        f = open(file, \"r\")\n",
    "        self.y = []\n",
    "        self.feature_ids = []\n",
    "        self.feature_values = []\n",
    "        self.ins_feature_interval = []\n",
    "        self.ins_feature_interval.append(0)\n",
    "        for line in f.readlines():\n",
    "            tokens = line.split(\" \")\n",
    "            self.y.append(float(tokens[0]))\n",
    "            #print(tokens[0])\n",
    "            self.ins_feature_interval.append(self.ins_feature_interval[-1] + len(tokens) - 1)\n",
    "            for feature in tokens[1:]:\n",
    "                try:\n",
    "                    feature_id, feature_value = feature.split(\":\")\n",
    "                    self.feature_ids.append(int(feature_id))\n",
    "                    self.feature_values.append(float(feature_value))\n",
    "                except:\n",
    "                    continue\n",
    "            self.ins_num += 1\n",
    "\n",
    "    def mini_batch(self, batch_size):\n",
    "        begin = self.iter\n",
    "        end = self.iter\n",
    "        if self.iter + batch_size > self.ins_num:\n",
    "            end = self.ins_num\n",
    "            self.iter = 0\n",
    "            self.epoch_pass += 1\n",
    "        else:\n",
    "            end += batch_size\n",
    "            self.iter = end\n",
    "        return self.slice(begin, end)\n",
    "\n",
    "    def slice(self, begin, end):\n",
    "        sparse_index = []\n",
    "        sparse_ids = []\n",
    "        sparse_values = []\n",
    "        sparse_shape = []\n",
    "        max_feature_num = 0\n",
    "        for i in range(begin, end):\n",
    "            feature_num = self.ins_feature_interval[i + 1] - self.ins_feature_interval[i]\n",
    "            if feature_num > max_feature_num:\n",
    "                max_feature_num = feature_num\n",
    "            for j in range(self.ins_feature_interval[i], self.ins_feature_interval[i + 1]):\n",
    "                sparse_index.append([i - begin, j - self.ins_feature_interval[i]]) # index must be accent\n",
    "                #print(len(sparse_index))\n",
    "                sparse_ids.append(self.feature_ids[j])\n",
    "                sparse_values.append(self.feature_values[j])\n",
    "        sparse_shape.append(end - begin)\n",
    "        sparse_shape.append(max_feature_num)\n",
    "        y = np.array(self.y[begin:end]).reshape((end - begin, 1))\n",
    "        return (sparse_index, sparse_ids, sparse_values, sparse_shape, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 645,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BinaryLogisticRegression(object):\n",
    "    def __init__(self, feature_num):\n",
    "        self.feature_num = feature_num\n",
    "        self.sparse_index = tf.placeholder(tf.int64)\n",
    "        self.sparse_ids = tf.placeholder(tf.int64)\n",
    "        self.sparse_values = tf.placeholder(tf.float32)\n",
    "        self.sparse_shape = tf.placeholder(tf.int64)\n",
    "        self.w = tf.Variable(tf.random_normal([self.feature_num, 1], stddev=0.1))\n",
    "        self.y = tf.placeholder(\"float\", [None, 1])\n",
    "\n",
    "    def forward(self):\n",
    "        return tf.nn.embedding_lookup_sparse(self.w,\n",
    "                                             tf.SparseTensor(self.sparse_index, self.sparse_ids, self.sparse_shape),\n",
    "                                             tf.SparseTensor(self.sparse_index, self.sparse_values, self.sparse_shape),\n",
    "                                             combiner=\"sum\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 646,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = []\n",
    "feature_ids = []\n",
    "feature_values = []\n",
    "ins_feature_interval = []\n",
    "\n",
    "def load(file):\n",
    "    ins_num = 0\n",
    "    f = open(file, \"r\")\n",
    "    ins_feature_interval.append(0)\n",
    "    for line in f.readlines():\n",
    "        tokens = line.split(\" \")\n",
    "        y.append(float(tokens[0]))\n",
    "        ins_feature_interval.append(ins_feature_interval[-1] + len(tokens) - 1)\n",
    "        for feature in tokens[1:]:\n",
    "            try:\n",
    "                feature_id, feature_value = feature.split(\":\")\n",
    "                feature_ids.append(int(feature_id))\n",
    "                feature_values.append(float(feature_value))\n",
    "            except:\n",
    "                continue\n",
    "        ins_num += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 647,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = DataSet()\n",
    "train_set.load(train_file, feature_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 648,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_set = DataSet()\n",
    "test_set.load(test_file, feature_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 649,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = BinaryLogisticRegression(feature_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 650,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = model.forward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 651,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = tf.reduce_sum(tf.nn.sigmoid_cross_entropy_with_logits(labels=y, logits=model.y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 652,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate).minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 653,
   "metadata": {},
   "outputs": [],
   "source": [
    "probability_output = tf.nn.sigmoid(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 654,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[None, None]"
      ]
     },
     "execution_count": 654,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "session = tf.Session()\n",
    "init_all_variable = tf.global_variables_initializer()\n",
    "init_local_variable = tf.local_variables_initializer()\n",
    "session.run([init_all_variable, init_local_variable])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 656,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:  10  Area Under the Curve score is:  0.5\n"
     ]
    }
   ],
   "source": [
    "while train_set.epoch_pass < max_iter:\n",
    "    try:\n",
    "        sparse_index, sparse_ids, sparse_values, sparse_shape, mb_y = train_set.mini_batch(batch_size)\n",
    "        _, loss_, prob_out = session.run([optimizer, loss, probability_output],\n",
    "                                         feed_dict={model.sparse_index: sparse_index,\n",
    "                                                    model.sparse_ids: sparse_ids,\n",
    "                                                    model.sparse_values: sparse_values,\n",
    "                                                    model.sparse_shape: sparse_shape,\n",
    "                                                    model.y: mb_y})\n",
    "    except:\n",
    "        continue\n",
    "        \n",
    "auc = roc_auc_score(mb_y, prob_out)\n",
    "print(\"epoch: \", train_set.epoch_pass, \" Area Under the Curve score is: \", auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
