{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Benchmarking on One Machine \n",
    "=========\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Typical User Experience**\n",
    "\n",
    "Laptop Specs:\n",
    "    \n",
    "    Intel Core i7\n",
    "    16gb RAM\n",
    "    NVIDIA GeForce GTX 965M 2GB GDDR5 memory \n",
    "    Microsoft Windows 10\n",
    "    Running Jupyter Notebooks and multiple programs in the background"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import HTML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<script>\n",
       "  function code_toggle() {\n",
       "    if (code_shown){\n",
       "      $('div.input').hide('500');\n",
       "      $('#toggleButton').val('Show Code')\n",
       "    } else {\n",
       "      $('div.input').show('500');\n",
       "      $('#toggleButton').val('Hide Code')\n",
       "    }\n",
       "    code_shown = !code_shown\n",
       "  }\n",
       "\n",
       "  $( document ).ready(function(){\n",
       "    code_shown=false;\n",
       "    $('div.input').hide()\n",
       "  });\n",
       "</script>\n",
       "<form action=\"javascript:code_toggle()\"><input type=\"submit\" id=\"toggleButton\" value=\"Show Code\"></form>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "HTML('''<script>\n",
    "  function code_toggle() {\n",
    "    if (code_shown){\n",
    "      $('div.input').hide('500');\n",
    "      $('#toggleButton').val('Show Code')\n",
    "    } else {\n",
    "      $('div.input').show('500');\n",
    "      $('#toggleButton').val('Hide Code')\n",
    "    }\n",
    "    code_shown = !code_shown\n",
    "  }\n",
    "\n",
    "  $( document ).ready(function(){\n",
    "    code_shown=false;\n",
    "    $('div.input').hide()\n",
    "  });\n",
    "</script>\n",
    "<form action=\"javascript:code_toggle()\"><input type=\"submit\" id=\"toggleButton\" value=\"Show Code\"></form>''')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Import Packages**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.simplefilter(action='ignore')\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import os\n",
    "\n",
    "import time #cpu time\n",
    "import psutil #memory usage\n",
    "#tensorflow\n",
    "import tensorflow as tf\n",
    "\n",
    "#Scikitlearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.datasets import load_svmlight_file\n",
    "from scipy.sparse import coo_matrix,csr_matrix,lil_matrix\n",
    "from sklearn import linear_model\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "# For Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "#displays better in jupyter notebooks\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Download data \n",
    "#!wget https://www.csie.ntu.edu.tw/~cjlin/libsvmtools/datasets/binary/a1a.t"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Class and Functions***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Data importing function\n",
    "def get_data(file):\n",
    "    data = load_svmlight_file(file)#avazu-app.tr.bz2\n",
    "    return data[0], data[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**For Importing Raw Individual File**\n",
    "\n",
    "(single file for raw sparse dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here is the memory baseline prior to importing data:\n",
      " svmem(total=17101512704, available=10098614272, percent=40.9, used=7002898432, free=10098614272)\n"
     ]
    }
   ],
   "source": [
    "mem_baseline=psutil.virtual_memory() #  physical memory usage\n",
    "print('Here is the memory baseline prior to importing data:\\n',mem_baseline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_location=os.getcwd()+'\\\\tensorflow-models\\\\data\\\\libsvm_data\\\\a1a.t'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y =get_data(file_location) #import raw data\n",
    "mem_InData=psutil.virtual_memory()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here is the memory usage after importing data:\n",
      " svmem(total=17101512704, available=10531102720, percent=38.4, used=6570409984, free=10531102720)\n",
      "\n",
      "The time took to import the raw data:\n",
      "511 ms ± 70.9 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "print('Here is the memory usage after importing data:\\n',mem_InData) #  physical memory usage\n",
    "print('\\nThe time took to import the raw data:')\n",
    "exec_time1 = %%timeit -o X, y =get_data(file_location) #import raw data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here is the sparse matrix format for the data:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<30956x123 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 429343 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('Here is the sparse matrix format for the data:')\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "#May not be appropriate for time dependant data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** For Importing Previously Seperated Training and Testing File**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_file_location=os.getcwd()+'\\\\tensorflow-models\\\\data\\\\libsvm_data\\\\a1a'\n",
    "test_file_location=os.getcwd()+'\\\\tensorflow-models\\\\data\\\\libsvm_data\\\\a1a.t'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here is the memory baseline prior to importing data:\n",
      "\n",
      " svmem(total=17101512704, available=10182381568, percent=40.5, used=6919131136, free=10182381568)\n"
     ]
    }
   ],
   "source": [
    "mem_baseline=psutil.virtual_memory() #  physical memory usage\n",
    "print('Here is the memory baseline prior to importing data:\\n\\n',mem_baseline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train=get_data(train_file_location)\n",
    "X_test, y_test=get_data(test_file_location)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here is the memory usage afer importing the data:\n",
      "\n",
      " svmem(total=17101512704, available=10163965952, percent=40.6, used=6937546752, free=10163965952)\n"
     ]
    }
   ],
   "source": [
    "mem_baseline=psutil.virtual_memory() #  physical memory usage\n",
    "print('Here is the memory usage afer importing the data:\\n\\n',mem_baseline)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Execute Logistic Regression in SciKit Learn\n",
    "-------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The parameters for the logistic regression (Gradient Descent) are:\n",
    "    \n",
    "    Regularization: L2\n",
    "    \n",
    "    Regularization Threshold (C): 1.0\n",
    "    \n",
    "    Tolerance: 0.001\n",
    "    \n",
    "    Fit Intercpt: Yes (True)\n",
    "    \n",
    "    Processors (n_jobs): 1\n",
    "    \n",
    "    Max Number of Iterations: 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate a logistic regression model, and fit with X and y\n",
    "\n",
    "model = linear_model.LogisticRegression(penalty='l2',\\\n",
    "                                        C=1.0,\\\n",
    "                                        tol=0.001,\\\n",
    "                                        fit_intercept=True,\\\n",
    "                                        n_jobs=1,\\\n",
    "                                        max_iter=100)\n",
    "\n",
    "model = model.fit(X_train, y_train.ravel())#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9.5 ms ± 66.4 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n",
      "\n",
      "The average time taken to execute the logistic regression: 9.5 ms ± 66.4 µs per loop (mean ± std. dev. of 7 runs, 100 loops each) seconds\n"
     ]
    }
   ],
   "source": [
    "exec_time2 = %%timeit -o model.fit(X_train, y_train.ravel())\n",
    "print('\\nThe average time taken to execute the logistic regression:',exec_time2,'seconds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "X has 123 features per sample; expecting 119",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-162-d312dea5aee6>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m#Setup variables for evaluation metrics\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0my_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0my_obs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0my_test\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0my_score\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python36\\site-packages\\sklearn\\linear_model\\base.py\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    279\u001b[0m             \u001b[0mPredicted\u001b[0m \u001b[1;32mclass\u001b[0m \u001b[0mlabel\u001b[0m \u001b[0mper\u001b[0m \u001b[0msample\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    280\u001b[0m         \"\"\"\n\u001b[1;32m--> 281\u001b[1;33m         \u001b[0mscores\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdecision_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    282\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mscores\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    283\u001b[0m             \u001b[0mindices\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mscores\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mint\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python36\\site-packages\\sklearn\\linear_model\\base.py\u001b[0m in \u001b[0;36mdecision_function\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    260\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mn_features\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    261\u001b[0m             raise ValueError(\"X has %d features per sample; expecting %d\"\n\u001b[1;32m--> 262\u001b[1;33m                              % (X.shape[1], n_features))\n\u001b[0m\u001b[0;32m    263\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    264\u001b[0m         scores = safe_sparse_dot(X, self.coef_.T,\n",
      "\u001b[1;31mValueError\u001b[0m: X has 123 features per sample; expecting 119"
     ]
    }
   ],
   "source": [
    "#Setup variables for evaluation metrics\n",
    "y_pred = model.predict(X_test)\n",
    "y_obs = y_test\n",
    "y_score = y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Model Metrics**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The correlation coefficient: 0.15665340805070027 \n",
      "The accuracy of the model: 0.850771456123433 \n",
      "The precision (tp / (tp + fp)): 0.7170191339375629 \n",
      "The recall (tp / (tp + fn)): 0.5886730053741215 \n",
      "The f1 score is: 0.646538024971623 \n",
      "The Area Under the Curve score is: 0.7582970003143532\n"
     ]
    }
   ],
   "source": [
    "r2=metrics.r2_score(y_obs, y_pred)\n",
    "accuracy=model.score(X_train, y_train)\n",
    "prec=metrics.precision_score(y_obs, y_pred, labels=None, pos_label=1)\n",
    "recall=metrics.recall_score(y_obs, y_pred, labels=None, pos_label=1)\n",
    "f1 = metrics.f1_score(y_obs,y_pred)\n",
    "ROC_AUC = metrics.roc_auc_score(y_obs, y_score)\n",
    "print('The correlation coefficient:',r2,\\\n",
    "      '\\nThe accuracy of the model:',accuracy,\\\n",
    "      '\\nThe precision (tp / (tp + fp)):',prec,\\\n",
    "      '\\nThe recall (tp / (tp + fn)):',recall,\\\n",
    "      '\\nThe f1 score is:',f1,\\\n",
    "      '\\nThe Area Under the Curve score is:',ROC_AUC)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Execute Logistic Regression in Tensorflow\n",
    "-------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here the GPU is used for the task but restricted to using only 75% of GPU resources in order to prevent crashing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpu_options = tf.GPUOptions(per_process_gpu_memory_fraction=0.75)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate =  0.001\n",
    "max_iter = 100\n",
    "batch_size = 30\n",
    "\n",
    "train_file = os.getcwd()+'\\\\tensorflow-models\\\\data\\\\libsvm_data\\\\a2a'\n",
    "test_file = os.getcwd()+'\\\\tensorflow-models\\\\data\\\\libsvm_data\\\\a2a.t'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Class and Functions***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataSet(object):\n",
    "    def __init__(self):\n",
    "        self.iter = 0\n",
    "        self.epoch_pass = 0\n",
    "\n",
    "    def load(self, file):\n",
    "        '''\n",
    "        '''\n",
    "        self.ins_num = 0 #<set at zero\n",
    "        f = open(file, \"r\")\n",
    "        self.y = []\n",
    "        self.feature_ids = []\n",
    "        self.feature_values = []\n",
    "        self.ins_feature_interval = []\n",
    "        self.max_ins_feature_interval = []\n",
    "        self.ins_feature_interval.append(0)#makes zero the starting value in ins_feature_interval\n",
    "        self.max_token=[]\n",
    "        for line in f.readlines():#iterating through open file\n",
    "            regexp = re.compile(r':')#<---If feature has a colon then do\n",
    "            tokens = line.split(\" \")#split lines in the file\n",
    "            #tokens.remove('\\n')\n",
    "            #print(tokens[0])\n",
    "            self.y.append(float(tokens[0]))#append to y the first value in tokens (+1,-1,1)\n",
    "            try:\n",
    "                tokens[-1] = tokens[-1].strip()#<----remove '\\n'\n",
    "                tokens.remove('') #<---remove '' empty in list\n",
    "            except:\n",
    "                pass\n",
    "            \n",
    "            #                         last value in list is that value + (line splits -1)<--maybe adjusting for return (\\n) or y value \n",
    "            #print(self.ins_feature_interval[-1]+ len(tokens)-1)#<----stacks the batch sizes\n",
    "            self.ins_feature_interval.append(self.ins_feature_interval[-1]+ len(tokens)-1)\n",
    "            #print(len(self.ins_feature_interval))\n",
    "            for feature in tokens:#(len(tokens)~16\n",
    "              #  print(feature)\n",
    "                if regexp.search(feature):#if there is a colon in feature\n",
    "                    self.max_token.append(feature)#check on size\n",
    "                    feature_id, feature_value = feature.split(\":\") #split on colon\n",
    "                    if feature_id:\n",
    "                        self.feature_ids.append(int(feature_id))#append to feature ids\n",
    "                        self.feature_values.append(float(feature_value)) #append feature values\n",
    "            self.ins_num += 1 #set ins_num to 1\n",
    "        self.feature_num=max(self.feature_ids)#modify feature_num to max of ids (maximum # of features)\n",
    "        #self.max_ins_feature_interval=max(self.ins_feature_interval)\n",
    "        print('the max number of features:',self.feature_num)\n",
    "    \n",
    "\n",
    "    def mini_batch(self, batch_size):\n",
    "        begin = self.iter #begins as 0 as defined above\n",
    "        end = self.iter #starts with 0 as defined above\n",
    "        if self.iter + batch_size > self.ins_num: #if 0 + batchsize(10) > ins_num(1) defined in def load\n",
    "            end = self.ins_num #set end to be ins_num(1) \n",
    "            self.iter = 0 #set iter to 0\n",
    "            self.epoch_pass += 1 #add +1 to epoch_pass \n",
    "        else:\n",
    "            end += batch_size#add batch size to end, which should be equal to batch size\n",
    "            #print('end:',end)\n",
    "            #print('batch_size:',batch_size)\n",
    "            self.iter = end#set self.iter to batch size\n",
    "            #(begin, end)setting bounds moving across batch length in data\n",
    "            #print((begin, end))#slicing action of data (0, 15) (15, 30) (30, 45) (60,...\n",
    "        return self.slice(begin, end)\n",
    "#Error\n",
    "    def slice(self, begin, end):\n",
    "            sparse_index = []\n",
    "            sparse_ids = []\n",
    "            sparse_values = []\n",
    "            sparse_shape = []\n",
    "            max_feature_num = 0\n",
    "            for i in range(begin, end):#within range begin, end\n",
    "            #              15,461,906,1351                  0,446,891,1338 =~15 supposed to be length of token\n",
    "            #          (token length + range number +1) - (token length + range number)\n",
    "                feature_num = self.ins_feature_interval[i + 1] - self.ins_feature_interval[i]\n",
    "                if feature_num > max_feature_num:\n",
    "                    max_feature_num = feature_num\n",
    "                                    #       0,446,891,1338                  15,461,906,1351\n",
    "                #(token length + range number) ,       (token length + range number +1)\n",
    "                #self.max_ins_feature_interval-len(self.feature_ids)<-------------------\n",
    "                #print(self.ins_feature_interval[i],self.ins_feature_interval[i + 1])\n",
    "                #print(self.feature_ids[i])\n",
    "                for j in range(self.ins_feature_interval[i], self.ins_feature_interval[i + 1]):\n",
    "                #print(j,(len(self.feature_ids)))\n",
    "                #print(self.ins_feature_interval[i + 1])\n",
    "                #print(range(self.ins_feature_interval[i], self.ins_feature_interval[i + 1]))\n",
    "                #15 vals:                  0  , 0-14,446-460,891-905\n",
    "                    sparse_index.append([i - begin, j - self.ins_feature_interval[i]]) # index must be accent\n",
    "                    #[0, 0]-[0, 14][0, 0]-[0, 12]\n",
    "                    #print([i - begin, j - self.ins_feature_interval[i]])\n",
    "                    sparse_ids.append(self.feature_ids[j])\n",
    "                    sparse_values.append(self.feature_values[j])\n",
    "            sparse_shape.append(end - begin)\n",
    "            #print(end - begin)#<-----30\n",
    "            sparse_shape.append(max_feature_num)\n",
    "            #print(max_feature_num)#<-----15\n",
    "            #       Creates array shape of 30,1 of y values  (30, 1)\n",
    "            y = np.array(self.y[begin:end]).reshape((end - begin, 1))\n",
    "            #begin:0,30,60,90,120,150,180,210 intervals of 30\n",
    "            #end: 30,60,90,120,150,180,210,240\n",
    "            #            0            0                       0                 30            30\n",
    "            #print(len(sparse_index), len(sparse_ids), len(sparse_values), len(sparse_shape), len(y))\n",
    "            return (sparse_index, sparse_ids, sparse_values, sparse_shape, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BinaryLogisticRegression(object):\n",
    "    def __init__(self, feature_num):\n",
    "        self.feature_num = feature_num\n",
    "        self.sparse_index = tf.placeholder(tf.int64)\n",
    "        self.sparse_ids = tf.placeholder(tf.int64)\n",
    "        self.sparse_values = tf.placeholder(tf.float32)\n",
    "        self.sparse_shape = tf.placeholder(tf.int64)\n",
    "        self.w = tf.Variable(tf.random_normal([self.feature_num, 1], stddev=0.1))\n",
    "        self.y = tf.placeholder(\"float\", [None, 1])\n",
    "\n",
    "    def forward(self):\n",
    "        return tf.nn.embedding_lookup_sparse(self.w,\n",
    "                                             tf.SparseTensor(self.sparse_index, self.sparse_ids, self.sparse_shape),\n",
    "                                             tf.SparseTensor(self.sparse_index, self.sparse_values, self.sparse_shape),\n",
    "                                             combiner=\"sum\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here is the memory baseline prior to importing data:\n",
      "\n",
      " svmem(total=17101512704, available=10327105536, percent=39.6, used=6774407168, free=10327105536)\n"
     ]
    }
   ],
   "source": [
    "mem_baseline=psutil.virtual_memory() #  physical memory usage\n",
    "print('Here is the memory baseline prior to importing data:\\n\\n',mem_baseline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the max number of features: 119\n",
      "the max number of features: 123\n"
     ]
    }
   ],
   "source": [
    "train_set = DataSet()\n",
    "train_set.load(train_file)\n",
    "test_set = DataSet()\n",
    "test_set.load(test_file)\n",
    "feature_num=test_set.feature_num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here is the memory usage after importing data:\n",
      " svmem(total=17101512704, available=10324746240, percent=39.6, used=6776766464, free=10324746240)\n"
     ]
    }
   ],
   "source": [
    "mem_baseline=psutil.virtual_memory() #  physical memory usage\n",
    "print('Here is the memory usage after importing data:\\n',mem_baseline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = BinaryLogisticRegression(feature_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = model.forward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = tf.reduce_sum(tf.nn.sigmoid_cross_entropy_with_logits(labels=y, logits=model.y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate).minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {},
   "outputs": [],
   "source": [
    "probability_output = tf.nn.sigmoid(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[None, None]"
      ]
     },
     "execution_count": 309,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "session = tf.Session()\n",
    "init_all_variable = tf.global_variables_initializer()\n",
    "init_local_variable = tf.local_variables_initializer()\n",
    "session.run([init_all_variable, init_local_variable])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_passes=5 #number of passes in for loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:  100  ROC AUC score is:  0.5\n",
      "epoch:  100  ROC AUC score is:  0.5\n",
      "epoch:  100  ROC AUC score is:  0.5\n",
      "epoch:  100  ROC AUC score is:  0.5\n",
      "epoch:  100  ROC AUC score is:  0.5\n",
      "\n",
      "The average time taken to execute logistic regression for 5 passes 0.004765605926513672 seconds with a standard deviation of +- 0.0035704615412940513\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "end_list=[]\n",
    "for i in range(0,num_passes):\n",
    "    while train_set.epoch_pass < max_iter:\n",
    "        sparse_index, sparse_ids, sparse_values, sparse_shape, mb_y = train_set.mini_batch(batch_size)\n",
    "        _, loss_, prob_out = session.run([optimizer, loss, probability_output],\n",
    "                                         feed_dict={model.sparse_index: sparse_index,\n",
    "                                                    model.sparse_ids: sparse_ids,\n",
    "                                                    model.sparse_values: sparse_values,\n",
    "                                                    model.sparse_shape: sparse_shape,\n",
    "                                                    model.y: mb_y})\n",
    "    end = time.time()\n",
    "    exec_time=(end - start)\n",
    "    end_list.append(exec_time) \n",
    "    \n",
    "    try:\n",
    "        auc = roc_auc_score(mb_y, prob_out)\n",
    "        print(\"epoch: \", train_set.epoch_pass, \" ROC AUC score is: \", auc)\n",
    "\n",
    "    except:\n",
    "        print('\\nValueError: Only one class present in y_true. ROC AUC score is not defined in that case.\\n')\n",
    "        print(mb_y.T)\n",
    "        print(prob_out.T,'\\n')\n",
    "\n",
    "print('\\nThe average time taken to execute logistic regression for '+str(num_passes)+' passes',np.array(end_list).mean(),'seconds with a standard deviation of +- '+str(np.array(end_list).std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
